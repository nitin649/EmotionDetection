{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22746,
     "status": "ok",
     "timestamp": 1580956892849,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "RYjybSeaxSpo",
    "outputId": "6ae16cda-6125-4300-85ea-f5721dec4b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing All Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6556,
     "status": "ok",
     "timestamp": 1580956894912,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "Qz8BT0zNyDKL",
    "outputId": "abed0354-0e54-4ba1-c796-a776f3835eb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras  import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D,BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57VjHZ_cyMgc"
   },
   "outputs": [],
   "source": [
    "X_data=pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/EmotionDataset/emotionX.pkl\",\"rb\"))\n",
    "y_data=pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/EmotionDataset/emotionY.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2771,
     "status": "ok",
     "timestamp": 1580906918828,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "-9Wppuh3uS4F",
    "outputId": "41a38f87-7be7-4788-ecc7-0261890f0448"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3935,
     "status": "ok",
     "timestamp": 1580919309732,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "wdGqCMJ8egAg",
    "outputId": "3e5dfcfd-3030-4a19-e073-e32a839e0482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (40000, 48, 48, 1)\n",
      "len of y 40000\n",
      "len of X 40000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X\",X_data.shape)\n",
    "print(\"len of y\",len(y_data))\n",
    "print(\"len of X\",len(X_data))\n",
    "print(y_data.count(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNAkpVeOyfX_"
   },
   "outputs": [],
   "source": [
    "X_data=X_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8bjrBe1yiy-"
   },
   "outputs": [],
   "source": [
    "y_label=tf.keras.utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7e0WoxmDtvW1"
   },
   "outputs": [],
   "source": [
    "training_x=X_data[:25000]\n",
    "training_y=y_label[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1580919309735,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "3caNj_d4t7bz",
    "outputId": "6df62a7f-68c4-4ed7-cb66-5e52f6a4ea98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n",
      "(25000, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(training_x))\n",
    "print(len(training_y))\n",
    "print(training_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1726,
     "status": "ok",
     "timestamp": 1580919312018,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "tC1MsfMwuBQJ",
    "outputId": "4e0659b4-513c-4ca7-aabb-b0e2455605db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJARf7I6TEP4fIAXt2BJ6C48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(training_x[22432].reshape(48,48))\n",
    "plt.show()\n",
    "print(training_y[22432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1713,
     "status": "ok",
     "timestamp": 1580919313723,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "7K7FMcCQzdIv",
    "outputId": "a5d91687-4520-4d6e-ede6-57ddc0b41fb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1343,
     "status": "ok",
     "timestamp": 1580919314336,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "OUftFW9ve2aQ",
    "outputId": "1ab4feb2-a162-4509-c11b-1dd9f63e05f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#categories\n",
    "category=['angry','happy','sad','surprise','neutral']\n",
    "print(len(category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2970,
     "status": "ok",
     "timestamp": 1580919318642,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "Be1K_ojGzd-6",
    "outputId": "79c1954d-61f6-4e87-a10e-1ae1ae87c9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "num_features = 64\n",
    "num_labels=5\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=training_x.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_features,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1uI4DvLztUq"
   },
   "outputs": [],
   "source": [
    "checkpoint_path=\"/content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\"\n",
    "checkpoint_callback=callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            )\n",
    "early_checkpoints=callbacks.EarlyStopping(monitor='val_acc',  \n",
    "                                                          patience=6, \n",
    "                                                          verbose=1,\n",
    "                                                          mode='auto',\n",
    "                                                          restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 613000,
     "status": "error",
     "timestamp": 1580787976175,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "Fi3ceNFSzzUg",
    "outputId": "1c7032f9-79d7-452d-f8d8-5e8b8e09882d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.6773 - acc: 0.2171\n",
      "Epoch 00001: val_acc improved from -inf to 0.20500, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 812s 41ms/sample - loss: 1.6772 - acc: 0.2171 - val_loss: 1.6098 - val_acc: 0.2050\n",
      "Epoch 2/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.5904 - acc: 0.2423\n",
      "Epoch 00002: val_acc did not improve from 0.20500\n",
      "20000/20000 [==============================] - 807s 40ms/sample - loss: 1.5904 - acc: 0.2421 - val_loss: 1.6024 - val_acc: 0.1974\n",
      "Epoch 3/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.4947 - acc: 0.3027\n",
      "Epoch 00003: val_acc improved from 0.20500 to 0.31900, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 813s 41ms/sample - loss: 1.4945 - acc: 0.3029 - val_loss: 1.4300 - val_acc: 0.3190\n",
      "Epoch 4/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.4058 - acc: 0.3520\n",
      "Epoch 00004: val_acc improved from 0.31900 to 0.40320, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 805s 40ms/sample - loss: 1.4056 - acc: 0.3519 - val_loss: 1.3350 - val_acc: 0.4032\n",
      "Epoch 5/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.3453 - acc: 0.4028\n",
      "Epoch 00005: val_acc improved from 0.40320 to 0.46840, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 806s 40ms/sample - loss: 1.3452 - acc: 0.4030 - val_loss: 1.3075 - val_acc: 0.4684\n",
      "Epoch 6/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.2649 - acc: 0.4506\n",
      "Epoch 00006: val_acc improved from 0.46840 to 0.48780, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 801s 40ms/sample - loss: 1.2649 - acc: 0.4505 - val_loss: 1.2521 - val_acc: 0.4878\n",
      "Epoch 7/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.1989 - acc: 0.5004\n",
      "Epoch 00007: val_acc improved from 0.48780 to 0.54620, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 803s 40ms/sample - loss: 1.1988 - acc: 0.5005 - val_loss: 1.1071 - val_acc: 0.5462\n",
      "Epoch 8/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.1302 - acc: 0.5323\n",
      "Epoch 00008: val_acc improved from 0.54620 to 0.55960, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 804s 40ms/sample - loss: 1.1303 - acc: 0.5324 - val_loss: 1.0755 - val_acc: 0.5596\n",
      "Epoch 9/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 1.0784 - acc: 0.5604\n",
      "Epoch 00009: val_acc improved from 0.55960 to 0.56640, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 802s 40ms/sample - loss: 1.0784 - acc: 0.5603 - val_loss: 1.0365 - val_acc: 0.5664\n",
      "Epoch 10/100\n",
      " 4608/20000 [=====>........................] - ETA: 9:45 - loss: 1.0476 - acc: 0.5766"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-360a8ad96a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_checkpoints\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(training_x,training_y,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=[checkpoint_callback,early_checkpoints],validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7875,
     "status": "ok",
     "timestamp": 1580919330919,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "VG8ivtbBz7Cg",
    "outputId": "c04e96f7-ee81-48bf-9e20-a3de9a409f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model_change=tf.keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 662052,
     "status": "error",
     "timestamp": 1580696173127,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "OF_pEnAb5OEZ",
    "outputId": "f03ffdc0-66d9-407d-8a07-3c0f11baee58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2316 - acc: 0.9214\n",
      "Epoch 00001: val_acc improved from -inf to 0.81020, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\n",
      "20000/20000 [==============================] - 833s 42ms/sample - loss: 0.2315 - acc: 0.9215 - val_loss: 0.7386 - val_acc: 0.8102\n",
      "Epoch 2/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2311 - acc: 0.9206\n",
      "Epoch 00002: val_acc did not improve from 0.81020\n",
      "20000/20000 [==============================] - 828s 41ms/sample - loss: 0.2308 - acc: 0.9207 - val_loss: 0.7590 - val_acc: 0.8064\n",
      "Epoch 3/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2306 - acc: 0.9227\n",
      "Epoch 00003: val_acc did not improve from 0.81020\n",
      "20000/20000 [==============================] - 828s 41ms/sample - loss: 0.2308 - acc: 0.9226 - val_loss: 0.7292 - val_acc: 0.8072\n",
      "Epoch 4/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2262 - acc: 0.9262\n",
      "Epoch 00004: val_acc did not improve from 0.81020\n",
      "20000/20000 [==============================] - 826s 41ms/sample - loss: 0.2267 - acc: 0.9261 - val_loss: 0.7826 - val_acc: 0.8074\n",
      "Epoch 5/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2119 - acc: 0.9302\n",
      "Epoch 00005: val_acc did not improve from 0.81020\n",
      "20000/20000 [==============================] - 821s 41ms/sample - loss: 0.2126 - acc: 0.9300 - val_loss: 0.7821 - val_acc: 0.7960\n",
      "Epoch 6/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2180 - acc: 0.9256\n",
      "Epoch 00006: val_acc did not improve from 0.81020\n",
      "20000/20000 [==============================] - 823s 41ms/sample - loss: 0.2178 - acc: 0.9257 - val_loss: 0.7418 - val_acc: 0.7962\n",
      "Epoch 7/100\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2166 - acc: 0.9305"
     ]
    }
   ],
   "source": [
    "history=model_change.fit(training_x,training_y,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=[checkpoint_callback,early_checkpoints],validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5974,
     "status": "ok",
     "timestamp": 1580956909348,
     "user": {
      "displayName": "Nitin Sharma",
      "photoUrl": "",
      "userId": "04463361370995784787"
     },
     "user_tz": -330
    },
    "id": "baLP1Y0M5cBc",
    "outputId": "d2216898-5d3f-473f-d90a-ef3d63ad0b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model_for_testing=tf.keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/Emotion_recog/model_checkpoint2.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx5stqvcX-dC"
   },
   "outputs": [],
   "source": [
    "model_for_testing.save(\"/content/drive/My Drive/Colab Notebooks/Emotion_recog/model_testing.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOFOgm_fYIwq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5IeJOfLGANB/q8tbGAyUO",
   "name": "Emotion3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
